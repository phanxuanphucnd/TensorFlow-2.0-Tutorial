{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6df4128",
   "metadata": {},
   "source": [
    "## 3.2.4 Gradient Boosted Decision Trees (GBDT)\n",
    "\n",
    "- Author: Phanxuan Phuc\n",
    "- Project: https://github.com/phanxuanphucnd/TensorFlow-2.0-Tutorial\n",
    "\n",
    "\n",
    "### Dataset\n",
    "\n",
    "- Boston Housing Dataset: [Reference](https://www.cs.toronto.edu/~delve/data/boston/bostonDetail.html)\n",
    "\n",
    "- Description:\n",
    "\n",
    "    The dataset contains information collected by the U.S Census Service concerning housing in the area of Boston Mass. It was obtained from the StatLib archive (http://lib.stat.cmu.edu/datasets/boston), and has been used extensively throughout the literature to benchmark algorithms. However, these comparisons were primarily done outside of Delve and are thus somewhat suspect. The dataset is small in size with only 506 cases.\n",
    "\n",
    "    The data was originally published by Harrison, D. and Rubinfeld, D.L. `Hedonic prices and the demand for clean air', J. Environ. Economics & Management, vol.5, 81-102, 1978.`\n",
    "\n",
    "    *For the full features list, please see the link above*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "501ed33e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-07 00:56:44.356323: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-07-07 00:56:44.356349: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import copy\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Ignore all GPUs because the current TF GBDT doesn't support GPU\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = ''\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dfa2d316",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset parameters\n",
    "num_classes = 2    # Total classes: greater or equal to $23,000, or NOT \n",
    "num_features = 13  # Data features size\n",
    "\n",
    "# Training parameters\n",
    "max_steps = 2000\n",
    "batch_size = 256\n",
    "learning_rate = 1.0\n",
    "l1_regular = 0.0\n",
    "l2_regular = 0.1\n",
    "\n",
    "# GBDT parameters\n",
    "num_batches_per_layer = 1000\n",
    "num_trees = 10\n",
    "max_depth = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e265d220",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare Boston Housing Dataset\n",
    "\n",
    "from tensorflow.keras.datasets import boston_housing\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = boston_housing.load_data()\n",
    "\n",
    "\n",
    "# For classification purpose, we build 2 classes: price greater or lower than $23,000\n",
    "def to_binary_class(y):\n",
    "    for i, label in enumerate(y):\n",
    "        if label >= 23.0:\n",
    "            y[i] = 1\n",
    "        else:\n",
    "            y[i] = 0\n",
    "            \n",
    "y_train_binary = to_binary_class(copy.deepcopy(y_train))\n",
    "y_test_binary = to_binary_class(copy.deepcopy(y_y))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2",
   "language": "python",
   "name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
