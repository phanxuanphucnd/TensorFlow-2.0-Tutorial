{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6df4128",
   "metadata": {},
   "source": [
    "## 3.2.4 Gradient Boosted Decision Trees (GBDT)\n",
    "\n",
    "- Author: Phanxuan Phuc\n",
    "- Project: https://github.com/phanxuanphucnd/TensorFlow-2.0-Tutorial\n",
    "\n",
    "\n",
    "### Dataset\n",
    "\n",
    "- Boston Housing Dataset: [Reference](https://www.cs.toronto.edu/~delve/data/boston/bostonDetail.html)\n",
    "\n",
    "- Description:\n",
    "\n",
    "    The dataset contains information collected by the U.S Census Service concerning housing in the area of Boston Mass. It was obtained from the StatLib archive (http://lib.stat.cmu.edu/datasets/boston), and has been used extensively throughout the literature to benchmark algorithms. However, these comparisons were primarily done outside of Delve and are thus somewhat suspect. The dataset is small in size with only 506 cases.\n",
    "\n",
    "    The data was originally published by Harrison, D. and Rubinfeld, D.L. `Hedonic prices and the demand for clean air', J. Environ. Economics & Management, vol.5, 81-102, 1978.`\n",
    "\n",
    "    *For the full features list, please see the link above*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "501ed33e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-07 01:29:40.669440: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-07-07 01:29:40.669466: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import copy\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Ignore all GPUs because the current TF GBDT doesn't support GPU\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = ''\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0e63165",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset parameters\n",
    "num_classes = 2    # Total classes: greater or equal to $23,000, or NOT \n",
    "num_features = 13  # Data features size\n",
    "\n",
    "# Training parameters\n",
    "max_steps = 2000\n",
    "batch_size = 256\n",
    "learning_rate = 1.0\n",
    "l1_regular = 0.0\n",
    "l2_regular = 0.1\n",
    "\n",
    "# GBDT parameters\n",
    "num_batches_per_layer = 1000\n",
    "num_trees = 10\n",
    "max_depth = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3c9e704",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare Boston Housing Dataset\n",
    "\n",
    "from tensorflow.keras.datasets import boston_housing\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = boston_housing.load_data()\n",
    "\n",
    "\n",
    "# For classification purpose, we build 2 classes: price greater or lower than $23,000\n",
    "def to_binary_class(y):\n",
    "    for i, label in enumerate(y):\n",
    "        if label >= 23.0:\n",
    "            y[i] = 1\n",
    "        else:\n",
    "            y[i] = 0\n",
    "            \n",
    "    return y\n",
    "            \n",
    "y_train_binary = to_binary_class(copy.deepcopy(y_train))\n",
    "y_test_binary = to_binary_class(copy.deepcopy(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a14df4",
   "metadata": {},
   "source": [
    "### GBDT Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c1ae475",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/phucphan/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/util/lazy_loader.py:63: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\n",
      "\n",
      "WARNING:tensorflow:From /tmp/ipykernel_22423/1851384762.py:3: The name tf.estimator.inputs.numpy_input_fn is deprecated. Please use tf.compat.v1.estimator.inputs.numpy_input_fn instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Build the Input function\n",
    "\n",
    "train_input_fn = tf.compat.v1.estimator.inputs.numpy_input_fn(\n",
    "    x={'x': x_train}, y=y_train_binary,\n",
    "    batch_size=batch_size, num_epochs=None, shuffle=True\n",
    ")\n",
    "\n",
    "test_input_fn = tf.compat.v1.estimator.inputs.numpy_input_fn(\n",
    "    x={'x': x_test}, y=y_test_binary,\n",
    "    batch_size=batch_size, num_epochs=1, shuffle=False\n",
    ")\n",
    "\n",
    "test_train_input_fn = tf.compat.v1.estimator.inputs.numpy_input_fn(\n",
    "    x={'x': x_train}, y=y_train_binary,\n",
    "    batch_size=batch_size, num_epochs=1, shuffle=False\n",
    ")\n",
    "\n",
    "# GBDT models from TF Estimator requires `feature_column` data format\n",
    "feature_columns = [tf.feature_column.numeric_column(key='x', shape=(num_features, ))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f6d4c47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpuymq6v22\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmpuymq6v22', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "gbdt_classifier = tf.estimator.BoostedTreesClassifier(\n",
    "    n_batches_per_layer=num_batches_per_layer,\n",
    "    feature_columns=feature_columns,\n",
    "    n_classes=num_classes,\n",
    "    learning_rate=learning_rate,\n",
    "    n_trees=num_trees,\n",
    "    max_depth=max_depth,\n",
    "    l1_regularization=l1_regular,\n",
    "    l2_regularization=l2_regular\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44f169d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/phucphan/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "WARNING:tensorflow:From /home/phucphan/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/inputs/queues/feeding_queue_runner.py:65: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From /home/phucphan/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/inputs/queues/feeding_functions.py:491: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-07 01:29:42.099823: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2021-07-07 01:29:42.099851: W tensorflow/stream_executor/cuda/cuda_driver.cc:326] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2021-07-07 01:29:42.099872: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (phucphan-ThinkPad): /proc/driver/nvidia/version does not exist\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "WARNING:tensorflow:Issue encountered when serializing resources.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "'_Resource' object has no attribute 'name'\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function CapturableResource.__del__ at 0x7f493e1039d8>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/phucphan/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/training/tracking/tracking.py\", line 269, in __del__\n",
      "    with self._destruction_context():\n",
      "AttributeError: 'TreeEnsemble' object has no attribute '_destruction_context'\n",
      "2021-07-07 01:29:42.494282: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-07-07 01:29:42.535832: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 1999965000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n",
      "WARNING:tensorflow:From /home/phucphan/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/training/monitored_session.py:907: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:Issue encountered when serializing resources.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "'_Resource' object has no attribute 'name'\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmpuymq6v22/model.ckpt.\n",
      "WARNING:tensorflow:Issue encountered when serializing resources.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "'_Resource' object has no attribute 'name'\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n",
      "INFO:tensorflow:loss = 0.6931473, step = 0\n",
      "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
      "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
      "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
      "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
      "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
      "INFO:tensorflow:loss = 0.6931473, step = 0 (0.385 sec)\n",
      "INFO:tensorflow:loss = 0.6931473, step = 0 (0.105 sec)\n",
      "INFO:tensorflow:loss = 0.6931473, step = 0 (0.168 sec)\n",
      "INFO:tensorflow:loss = 0.6931473, step = 0 (0.192 sec)\n",
      "INFO:tensorflow:loss = 0.6931473, step = 0 (0.192 sec)\n",
      "INFO:tensorflow:loss = 0.6931473, step = 0 (0.175 sec)\n",
      "INFO:tensorflow:loss = 0.6931473, step = 0 (0.163 sec)\n",
      "INFO:tensorflow:loss = 0.6931473, step = 0 (0.162 sec)\n",
      "INFO:tensorflow:loss = 0.6931473, step = 0 (0.152 sec)\n",
      "INFO:tensorflow:loss = 0.6931473, step = 0 (0.152 sec)\n",
      "INFO:tensorflow:global_step/sec: 48.3799\n",
      "INFO:tensorflow:loss = 0.6931473, step = 100 (0.223 sec)\n",
      "INFO:tensorflow:global_step/sec: 797.549\n",
      "INFO:tensorflow:loss = 0.6931473, step = 200 (0.126 sec)\n",
      "INFO:tensorflow:global_step/sec: 775.957\n",
      "INFO:tensorflow:loss = 0.6931473, step = 300 (0.129 sec)\n",
      "INFO:tensorflow:global_step/sec: 763.57\n",
      "INFO:tensorflow:loss = 0.6931473, step = 400 (0.131 sec)\n",
      "INFO:tensorflow:global_step/sec: 747.261\n",
      "INFO:tensorflow:loss = 0.6931473, step = 500 (0.134 sec)\n",
      "INFO:tensorflow:global_step/sec: 768.468\n",
      "INFO:tensorflow:loss = 0.6931473, step = 600 (0.130 sec)\n",
      "INFO:tensorflow:global_step/sec: 760.298\n",
      "INFO:tensorflow:loss = 0.6931473, step = 700 (0.132 sec)\n",
      "INFO:tensorflow:global_step/sec: 767.53\n",
      "INFO:tensorflow:loss = 0.6931473, step = 800 (0.130 sec)\n",
      "INFO:tensorflow:global_step/sec: 775.956\n",
      "INFO:tensorflow:loss = 0.6931473, step = 900 (0.129 sec)\n",
      "INFO:tensorflow:global_step/sec: 713.192\n",
      "INFO:tensorflow:loss = 0.45322615, step = 1000 (0.141 sec)\n",
      "INFO:tensorflow:global_step/sec: 819.47\n",
      "INFO:tensorflow:loss = 0.48778844, step = 1100 (0.122 sec)\n",
      "INFO:tensorflow:global_step/sec: 799.174\n",
      "INFO:tensorflow:loss = 0.47128764, step = 1200 (0.125 sec)\n",
      "INFO:tensorflow:global_step/sec: 818.005\n",
      "INFO:tensorflow:loss = 0.49758488, step = 1300 (0.122 sec)\n",
      "INFO:tensorflow:global_step/sec: 731.61\n",
      "INFO:tensorflow:loss = 0.46307075, step = 1400 (0.137 sec)\n",
      "INFO:tensorflow:global_step/sec: 792.131\n",
      "INFO:tensorflow:loss = 0.42667115, step = 1500 (0.129 sec)\n",
      "INFO:tensorflow:global_step/sec: 577.128\n",
      "INFO:tensorflow:loss = 0.4522834, step = 1600 (0.171 sec)\n",
      "INFO:tensorflow:global_step/sec: 529.843\n",
      "INFO:tensorflow:loss = 0.48437172, step = 1700 (0.188 sec)\n",
      "INFO:tensorflow:global_step/sec: 598.339\n",
      "INFO:tensorflow:loss = 0.47892702, step = 1800 (0.168 sec)\n",
      "INFO:tensorflow:global_step/sec: 489.472\n",
      "INFO:tensorflow:loss = 0.48106238, step = 1900 (0.203 sec)\n",
      "INFO:tensorflow:global_step/sec: 678.711\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 2000...\n",
      "INFO:tensorflow:Saving checkpoints for 2000 into /tmp/tmpuymq6v22/model.ckpt.\n",
      "WARNING:tensorflow:Issue encountered when serializing resources.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "'_Resource' object has no attribute 'name'\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 2000...\n",
      "INFO:tensorflow:Loss for final step: 0.4687842.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.canned.boosted_trees.BoostedTreesClassifier at 0x7f4933ac0518>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbdt_classifier.train(\n",
    "    train_input_fn,\n",
    "    max_steps=max_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d0795ec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:From /home/phucphan/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/canned/head.py:642: auc (from tensorflow.python.ops.metrics_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The value of AUC returned by this may race with the update so this is deprecated. Please use tf.keras.metrics.AUC instead.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2021-07-07T01:29:48\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpuymq6v22/model.ckpt-2000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function CapturableResource.__del__ at 0x7f493e1039d8>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/phucphan/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/training/tracking/tracking.py\", line 269, in __del__\n",
      "    with self._destruction_context():\n",
      "AttributeError: 'TreeEnsemble' object has no attribute '_destruction_context'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Inference Time : 0.47890s\n",
      "INFO:tensorflow:Finished evaluation at 2021-07-07-01:29:48\n",
      "INFO:tensorflow:Saving dict for global step 2000: accuracy = 0.87376237, accuracy_baseline = 0.63118815, auc = 0.92280567, auc_precision_recall = 0.9104949, average_loss = 0.38152993, global_step = 2000, label/mean = 0.36881188, loss = 0.38536403, precision = 0.8888889, prediction/mean = 0.37860456, recall = 0.7516779\n",
      "WARNING:tensorflow:Issue encountered when serializing resources.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "'_Resource' object has no attribute 'name'\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 2000: /tmp/tmpuymq6v22/model.ckpt-2000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.87376237,\n",
       " 'accuracy_baseline': 0.63118815,\n",
       " 'auc': 0.92280567,\n",
       " 'auc_precision_recall': 0.9104949,\n",
       " 'average_loss': 0.38152993,\n",
       " 'label/mean': 0.36881188,\n",
       " 'loss': 0.38536403,\n",
       " 'precision': 0.8888889,\n",
       " 'prediction/mean': 0.37860456,\n",
       " 'recall': 0.7516779,\n",
       " 'global_step': 2000}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbdt_classifier.evaluate(test_train_input_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1358449c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2021-07-07T01:29:49\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpuymq6v22/model.ckpt-2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function CapturableResource.__del__ at 0x7f493e1039d8>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/phucphan/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/training/tracking/tracking.py\", line 269, in __del__\n",
      "    with self._destruction_context():\n",
      "AttributeError: 'TreeEnsemble' object has no attribute '_destruction_context'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 0.42627s\n",
      "INFO:tensorflow:Finished evaluation at 2021-07-07-01:29:49\n",
      "INFO:tensorflow:Saving dict for global step 2000: accuracy = 0.78431374, accuracy_baseline = 0.5588235, auc = 0.8458089, auc_precision_recall = 0.8628531, average_loss = 0.4937335, global_step = 2000, label/mean = 0.44117647, loss = 0.4937335, precision = 0.87096775, prediction/mean = 0.37429, recall = 0.6\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 2000: /tmp/tmpuymq6v22/model.ckpt-2000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.78431374,\n",
       " 'accuracy_baseline': 0.5588235,\n",
       " 'auc': 0.8458089,\n",
       " 'auc_precision_recall': 0.8628531,\n",
       " 'average_loss': 0.4937335,\n",
       " 'label/mean': 0.44117647,\n",
       " 'loss': 0.4937335,\n",
       " 'precision': 0.87096775,\n",
       " 'prediction/mean': 0.37429,\n",
       " 'recall': 0.6,\n",
       " 'global_step': 2000}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbdt_classifier.evaluate(test_input_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "798bb6c5",
   "metadata": {},
   "source": [
    "### GBDT Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae8bb676",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the input function.\n",
    "\n",
    "train_input_fn = tf.compat.v1.estimator.inputs.numpy_input_fn(\n",
    "    x={'x': x_train}, y=y_train,\n",
    "    batch_size=batch_size, num_epochs=None, shuffle=True\n",
    ")\n",
    "\n",
    "test_input_fn = tf.compat.v1.estimator.inputs.numpy_input_fn(\n",
    "    x={'x': x_test}, y=y_test,\n",
    "    batch_size=batch_size, num_epochs=1, shuffle=False\n",
    ")\n",
    "\n",
    "# GBDT models from TF Estimator requires `feature_column` data format\n",
    "feature_columns = [tf.feature_column.numeric_column(key='x', shape=(num_features,))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "049a091f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpwq46lp_b\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmpwq46lp_b', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "gbdt_regressor = tf.estimator.BoostedTreesRegressor(\n",
    "    n_batches_per_layer=num_batches_per_layer,\n",
    "    feature_columns=feature_columns, \n",
    "    learning_rate=learning_rate, \n",
    "    n_trees=num_trees,\n",
    "    max_depth=max_depth,\n",
    "    l1_regularization=l1_regular, \n",
    "    l2_regularization=l2_regular\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c62f576",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "WARNING:tensorflow:Issue encountered when serializing resources.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "'_Resource' object has no attribute 'name'\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function CapturableResource.__del__ at 0x7f493e1039d8>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/phucphan/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/training/tracking/tracking.py\", line 269, in __del__\n",
      "    with self._destruction_context():\n",
      "AttributeError: 'TreeEnsemble' object has no attribute '_destruction_context'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Issue encountered when serializing resources.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "'_Resource' object has no attribute 'name'\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmpwq46lp_b/model.ckpt.\n",
      "WARNING:tensorflow:Issue encountered when serializing resources.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "'_Resource' object has no attribute 'name'\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n",
      "INFO:tensorflow:loss = 569.7765, step = 0\n",
      "INFO:tensorflow:loss = 523.4455, step = 0 (0.247 sec)\n",
      "INFO:tensorflow:loss = 632.2858, step = 0 (0.114 sec)\n",
      "INFO:tensorflow:loss = 620.88464, step = 0 (0.121 sec)\n",
      "INFO:tensorflow:loss = 582.4016, step = 0 (0.116 sec)\n",
      "INFO:tensorflow:loss = 568.84973, step = 0 (0.119 sec)\n",
      "INFO:tensorflow:loss = 628.28766, step = 0 (0.155 sec)\n",
      "INFO:tensorflow:loss = 596.1156, step = 0 (0.138 sec)\n",
      "INFO:tensorflow:loss = 538.71844, step = 0 (0.121 sec)\n",
      "INFO:tensorflow:loss = 552.3838, step = 0 (0.120 sec)\n",
      "INFO:tensorflow:loss = 564.7405, step = 0 (0.119 sec)\n",
      "INFO:tensorflow:global_step/sec: 62.3676\n",
      "INFO:tensorflow:loss = 588.93726, step = 100 (0.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 805.075\n",
      "INFO:tensorflow:loss = 599.57983, step = 200 (0.125 sec)\n",
      "INFO:tensorflow:global_step/sec: 642.439\n",
      "INFO:tensorflow:loss = 600.2467, step = 300 (0.157 sec)\n",
      "INFO:tensorflow:global_step/sec: 606.693\n",
      "INFO:tensorflow:loss = 608.8026, step = 400 (0.164 sec)\n",
      "INFO:tensorflow:global_step/sec: 622.06\n",
      "INFO:tensorflow:loss = 633.68616, step = 500 (0.161 sec)\n",
      "INFO:tensorflow:global_step/sec: 664.521\n",
      "INFO:tensorflow:loss = 569.4494, step = 600 (0.151 sec)\n",
      "INFO:tensorflow:global_step/sec: 740.673\n",
      "INFO:tensorflow:loss = 620.26245, step = 700 (0.134 sec)\n",
      "INFO:tensorflow:global_step/sec: 755.103\n",
      "INFO:tensorflow:loss = 572.446, step = 800 (0.133 sec)\n",
      "INFO:tensorflow:global_step/sec: 741.388\n",
      "INFO:tensorflow:loss = 564.56226, step = 900 (0.135 sec)\n",
      "INFO:tensorflow:global_step/sec: 739.01\n",
      "INFO:tensorflow:loss = 68.07593, step = 1000 (0.136 sec)\n",
      "INFO:tensorflow:global_step/sec: 758.32\n",
      "INFO:tensorflow:loss = 45.89437, step = 1100 (0.131 sec)\n",
      "INFO:tensorflow:global_step/sec: 770.36\n",
      "INFO:tensorflow:loss = 56.494576, step = 1200 (0.130 sec)\n",
      "INFO:tensorflow:global_step/sec: 716.533\n",
      "INFO:tensorflow:loss = 46.900528, step = 1300 (0.139 sec)\n",
      "INFO:tensorflow:global_step/sec: 682.448\n",
      "INFO:tensorflow:loss = 73.72048, step = 1400 (0.147 sec)\n",
      "INFO:tensorflow:global_step/sec: 617.035\n",
      "INFO:tensorflow:loss = 69.38997, step = 1500 (0.162 sec)\n",
      "INFO:tensorflow:global_step/sec: 679.729\n",
      "INFO:tensorflow:loss = 56.16841, step = 1600 (0.147 sec)\n",
      "INFO:tensorflow:global_step/sec: 701.951\n",
      "INFO:tensorflow:loss = 51.602444, step = 1700 (0.143 sec)\n",
      "INFO:tensorflow:global_step/sec: 760.522\n",
      "INFO:tensorflow:loss = 51.197884, step = 1800 (0.131 sec)\n",
      "INFO:tensorflow:global_step/sec: 801.192\n",
      "INFO:tensorflow:loss = 63.299507, step = 1900 (0.125 sec)\n",
      "INFO:tensorflow:global_step/sec: 762.691\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 2000...\n",
      "INFO:tensorflow:Saving checkpoints for 2000 into /tmp/tmpwq46lp_b/model.ckpt.\n",
      "WARNING:tensorflow:Issue encountered when serializing resources.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "'_Resource' object has no attribute 'name'\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 2000...\n",
      "INFO:tensorflow:Loss for final step: 51.31961.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.canned.boosted_trees.BoostedTreesRegressor at 0x7f4912ac6e80>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbdt_regressor.train(train_input_fn, max_steps=max_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b2e2a30c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2021-07-07T01:31:29\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpwq46lp_b/model.ckpt-2000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function CapturableResource.__del__ at 0x7f493e1039d8>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/phucphan/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/training/tracking/tracking.py\", line 269, in __del__\n",
      "    with self._destruction_context():\n",
      "AttributeError: 'TreeEnsemble' object has no attribute '_destruction_context'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Inference Time : 0.19255s\n",
      "INFO:tensorflow:Finished evaluation at 2021-07-07-01:31:29\n",
      "INFO:tensorflow:Saving dict for global step 2000: average_loss = 29.69382, global_step = 2000, label/mean = 23.078432, loss = 29.69382, prediction/mean = 22.49272\n",
      "WARNING:tensorflow:Issue encountered when serializing resources.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "'_Resource' object has no attribute 'name'\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 2000: /tmp/tmpwq46lp_b/model.ckpt-2000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'average_loss': 29.69382,\n",
       " 'label/mean': 23.078432,\n",
       " 'loss': 29.69382,\n",
       " 'prediction/mean': 22.49272,\n",
       " 'global_step': 2000}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbdt_regressor.evaluate(test_input_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02c02bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2",
   "language": "python",
   "name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
